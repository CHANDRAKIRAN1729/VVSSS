{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fdb5a0d",
   "metadata": {},
   "source": [
    "## Python Script to Load and Use the .pt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BertModel  # or use AutoModel if unsure\n",
    "\n",
    "# Load tokenizer (assuming you're using MiniLMv2 with BERT-like tokenizer)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/MiniLMv2-L6-H384-distilled-from-BERT-Large\")\n",
    "\n",
    "# Define model architecture\n",
    "class MiniLMv2Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiniLMv2Model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"microsoft/MiniLMv2-L6-H384-distilled-from-BERT-Large\")\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        return self.bert(input_ids=input_ids,\n",
    "                         attention_mask=attention_mask,\n",
    "                         token_type_ids=token_type_ids)\n",
    "\n",
    "# Initialize and load weights\n",
    "model = MiniLMv2Model()\n",
    "model.load_state_dict(torch.load(\"minilm_model.pt\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# Sample input\n",
    "text = \"MiniLMv2 is a lightweight and fast transformer model.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "# Example: get embedding of [CLS] token\n",
    "cls_embedding = last_hidden_state[:, 0, :]  # shape: (1, hidden_size)\n",
    "print(\"CLS embedding shape:\", cls_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e78ed77",
   "metadata": {},
   "source": [
    "## What You Might Need to Adjust\n",
    "### If your .pt file saved the entire model (torch.save(model)), then you can load it directly with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb8251",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"minilm_model.pt\")\n",
    "model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
